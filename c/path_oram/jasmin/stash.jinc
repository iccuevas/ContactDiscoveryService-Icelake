require "consts.jinc"
require "util.jinc"
require "bucket.jinc"

// returns the index of the last nonempty blocks in overflow
fn _stash_overflow_ub(
  reg u64 stash,
  #msf reg u64 msf
) -> reg u64, #msf reg u64
{
  reg u64 i j overflow_blocks bid offset;
  reg u64 zero;
  reg u8 c;
  reg bool b cond;

  i, msf = stash_overflow_capacity(stash, msf);
  overflow_blocks, msf = stash_overflow_blocks(stash, msf);
  offset = i;
  offset *= 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
  overflow_blocks += offset;
  zero = #set0();
  while { cond = i > 0; } (cond) {
    msf = #update_msf(cond, msf);
    overflow_blocks -= 8 * DECRYPTED_BLOCK_SIZE_QWORDS; // (i - 1)
    #declassify bid = (64u)[overflow_blocks];
    bid = #protect(bid, msf);
    b = bid != EMPTY_BLOCK_ID;
    c = #SETcc(b);
    j = zero;
    j = _ternary(c, i, j);
    i -= 1;
    i = _ternary(c, zero, i);
  }
  msf = #update_msf(!cond, msf);
  return j, msf;
}

inline
fn _first_block_in_bucket_for_level(
  reg u64 stash,
  reg u64 level,
  #msf reg u64 msf
) -> reg u64, #msf reg u64
{
  reg u64 p offset;
  p, msf = stash_path_blocks(stash, msf);
  offset = level * BLOCKS_PER_BUCKET;
  offset *= DECRYPTED_BLOCK_SIZE_QWORDS * 8;
  p = #LEA(p + offset);
  return p, msf;
}

inline
fn _i_cond_copy_block(
  reg u8 cond,
  reg u64 dst,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] src
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS]
{
  reg u256 tmp va;
  reg u128 tmp128 va128;
  inline int i;
  for i = 0 to DECRYPTED_BLOCK_SIZE_QWORDS / 4 {
    va = (u256)[dst];
    tmp = _ternary256(cond, src[u256 i], va);
    (u256)[dst] = tmp;
    dst = #LEA(dst + 32);
  }
  va128 = (u128)[dst];
  tmp128 = _ternary128(cond, src[u128 (DECRYPTED_BLOCK_SIZE_QWORDS / 4) * 2], va128);
  (u128)[dst] = tmp128;
  return src;
}

inline
fn _i_cond_swap_blocks(
  reg u8 cond,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] a,
  reg u64 b
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS]
{
  reg u256 tmp rb;
  reg u128 tmp128 rb128;
  inline int i;
  for i = 0 to DECRYPTED_BLOCK_SIZE_QWORDS / 4 {
    rb = (u256)[b];
    tmp = _ternary256(cond, a[u256 i], rb);
    (u256)[b] = tmp;
    a[u256 i] = _ternary256(cond, rb, a[u256 i]);
    b = #LEA(b + 32);
  }
  rb128 = (u128)[b];
  tmp128 = _ternary128(cond, a[u128 (DECRYPTED_BLOCK_SIZE_QWORDS / 4) * 2], rb128);
  (u128)[b] = tmp128;
  a[u128 (DECRYPTED_BLOCK_SIZE_QWORDS / 4) * 2] =
    _ternary128(cond, rb128, a[u128 (DECRYPTED_BLOCK_SIZE_QWORDS / 4) * 2]);
  return a;
}

// Precondition: `target` is an empty block OR no block in the bucket has ID equal to `target_block_id`
// Postcondition: No block in the bucket has ID equal to `target_block_id`, `target` is either empty or `target->id == target_block_id`.
fn _i_stash_add_path_bucket(
  reg u64 stash bucket_store,
  reg u64 bucket_id target_block_id,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] target,
  #msf reg u64 msf
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS], #msf reg u64
{
  reg u64 lvl bucket_blocks bid;
  reg u8 c;
  reg bool cond;
  inline int i;

  lvl = tree_path_level(bucket_id);
  bucket_blocks, msf = _first_block_in_bucket_for_level(stash, lvl, msf);
  #update_after_call msf = bucket_store_read_bucket_blocks(bucket_store, bucket_id, bucket_blocks, msf);
  bucket_blocks = #protect(bucket_blocks, msf);
  target = #protect_ptr(target, msf);
  for i = 0 to BLOCKS_PER_BUCKET
  {
    bid = (64u)[bucket_blocks];
    cond = bid == target_block_id;
    c = #SETcc(cond);
    target = _i_cond_swap_blocks(c, target, bucket_blocks);
    bucket_blocks += 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
  }
  return target, msf;
}

// Precondition: `target` is an empty block OR no block in the overflow has ID equal to `target_block_id`
// Postcondition: No block in the overflow has ID equal to `target_block_id`, `target` is either empty or `target->id == target_block_id`.
fn _i_stash_scan_overflow_for_target(
  reg u64 stash,
  reg u64 target_block_id,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] target,
  #msf reg u64 msf
) -> reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS], #msf reg u64
{
  reg u64 ub i bid overflow_blocks;
  reg u8 c;
  reg bool b cond;

  #update_after_call ub, msf = _stash_overflow_ub(stash, msf);
  stash = #protect(stash, msf);
  target = #protect_ptr(target, msf);
  overflow_blocks, msf = stash_overflow_blocks(stash, msf);
  i = 0;
  while { cond = i < ub; } (cond) {
    msf = #update_msf(cond, msf);
    bid = (64u)[overflow_blocks];
    b = bid == target_block_id;
    c = #SETcc(b);
    target = _i_cond_swap_blocks(c, target, overflow_blocks);
    overflow_blocks += 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
    i += 1;
  }
  msf = #update_msf(!cond, msf);
  return target, msf;
}

// Precondition: there is no block with ID `new_block->id` anywhere in the stash - neither the path_Stash nor the overflow.
inline
fn _i_stash_add_block(
  reg u64 stash,
  reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS] new_block,
  #msf reg u64 msf,
  inline int length
) -> #public reg u32, reg ptr u64[DECRYPTED_BLOCK_SIZE_QWORDS], #msf reg u64
{
  reg u64 bid overflow_capacity overflow_blocks i r0 r1;
  reg u32 r;
  reg u8 c1 c2;
  reg bool b cond;

  overflow_blocks, msf = stash_overflow_blocks(stash, msf);
  overflow_capacity, msf = stash_overflow_capacity(stash, msf);

  c1 = 0; // inserted
  i = 0;
  while { cond = i < overflow_capacity; } (cond) {
    msf = #update_msf(cond, msf);
    bid = [overflow_blocks];
    // cond
    c1 = !c1;
    b = bid == EMPTY_BLOCK_ID;
    c2 = #SETcc(b);
    #declassify c2 = c2;
    c2 = #protect_8(c2, msf);
    c2 &= c1;
    new_block = _i_cond_copy_block(c2, overflow_blocks, new_block);
    c1 = !c1;
    c1 |= c2;
    i += 1;
    overflow_blocks = #LEA(overflow_blocks + 8 * DECRYPTED_BLOCK_SIZE_QWORDS);
  }
  msf = #update_msf(!cond, msf);
  r0 = (64u)err_SUCCESS;
  r1 = (64u)err_ORAM__STASH_EXHAUSTION;
  b = c1 == 0; // not inserted
  r0 = #CMOVcc(b, r1, r0);
  r = (32u)r0;
  return r, new_block, msf;
}

inline
fn _stash_assign_block_to_bucket_path(
  #spill_to_mmx reg u64 stash path,
  inline int index,
  #msf reg u64 msf
) -> #msf reg u64
{
  // spill_to_mmx variables
  #spill_to_mmx reg u64 bucket_assignments;
  // pointer variables
  reg u64 path_blocks bucket_occupancy;
  // temporary variables
  reg u64 r1 r2 bucket_id tree_bound tmp;
  // spill_to_mmx
  #spill_to_mmx reg u64 bid bpos;
  // boolean variables
  reg u8 c1 c2 c3;
  reg bool b;
  inline int max_level lvl offset;
  
  // the block cannot be assigned to this level or higher
  max_level = (index / BLOCKS_PER_BUCKET) + 1;

  path_blocks, msf = stash_path_blocks(stash, msf);
  offset = index * 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
  bid = (64u)[path_blocks + offset];
  bid = #protect(bid, msf);
  () = #spill(bid);
  bpos = (64u)[path_blocks + offset + 8];
  bpos = #protect(bpos, msf);
  () = #spill(bpos);

  bucket_occupancy, msf = stash_bucket_occupancy(stash, msf);
  bucket_assignments, msf = stash_bucket_assignments(stash, msf);
  () = #spill(path, stash, bucket_assignments);

  c1 = #set0_8(); // is_assigned
  for lvl = 0 to max_level {
    r2 = (64u)[bucket_occupancy + 8 * lvl];
    r2 = #protect(r2, msf);
    () = #unspill(path);
    bucket_id = (64u)[path + 8 + 8 * lvl];
    bucket_id = #protect(bucket_id, msf);

    c1 = !c1;
    // is_valid
    tree_bound = tree_path_lower_bound(bucket_id);
    () = #unspill(bpos);
    b = tree_bound <= bpos;
    c2 = #SETcc(b);
    c2 &= c1;
    tree_bound = tree_path_upper_bound(bucket_id);
    () = #unspill(bpos);
    b = tree_bound >= bpos;
    c3 = #SETcc(b);
    c2 &= c3;
    // bucket_has_room
    b = r2 < BLOCKS_PER_BUCKET;
    c3 = #SETcc(b);
    c2 &= c3;
    // not is_empty
    () = #unspill(bid);
    b = bid != EMPTY_BLOCK_ID;
    c3 = #SETcc(b);
    c2 &= c3;
    // is_assigned = cond | is_assigned;
    c1 = !c1;
    c1 |= c2;
    
    // If `b` is true, put it in the bucket: increment the bucket occupancy and set the bucket assignment
    // for this position.
    // increment this, it will only get saved if `b` is true.
    r1 = #LEA(r2 + 1);
    r1 = _ternary(c2, r1, r2);
    () = #unspill(bucket_assignments);
    (u64)[bucket_occupancy + 8 * lvl] = r1;
    r1 = (64u)[bucket_assignments + 8 * index];
    r1 = #protect(r1, msf);
    tmp = (64u)lvl;
    r1 = _ternary(c2, tmp, r1);
    (u64)[bucket_assignments + 8 * index] = r1;
  }

  return msf;
}

inline
fn _stash_assign_block_to_bucket_overflow(
  #spill_to_mmx reg u64 stash path,
  reg u64 index,
  #msf reg u64 msf,
  inline int length
) -> #msf reg u64
{
  // spill_to_mmx variables
  #spill_to_mmx reg u64 assignment_index bucket_assignments;
  // pointer variables
  reg u64 path_blocks bucket_occupancy;
  // temporary variables
  reg u64 r1 r2 bucket_id tree_bound tmp;
  // spill_to_mmx
  #spill_to_mmx reg u64 bid bpos;
  // boolean variables
  reg u8 c1 c2 c3;
  reg bool b cond;
  inline int lvl max_level;
  
  // the block cannot be assigned to this level or higher
  max_level = (64u)length;
  assignment_index = #LEA(BLOCKS_PER_BUCKET * length + index);

  path_blocks, msf = stash_path_blocks(stash, msf);
  tmp = assignment_index;
  tmp *= 8 * DECRYPTED_BLOCK_SIZE_QWORDS;
  bid = (64u)[path_blocks + tmp];
  bid = #protect(bid, msf);
  () = #spill(bid);
  bpos = (64u)[path_blocks + tmp + 8];
  bpos = #protect(bpos, msf);
  () = #spill(bpos);

  bucket_occupancy, msf = stash_bucket_occupancy(stash, msf);
  bucket_assignments, msf = stash_bucket_assignments(stash, msf);
  () = #spill(path, stash, assignment_index, bucket_assignments);

  c1 = #set0_8(); // is_assigned
  for lvl = 0 to max_level {
    r2 = (64u)[bucket_occupancy + 8 * lvl];
    r2 = #protect(r2, msf);
    () = #unspill(path);
    bucket_id = (64u)[path + 8 + 8 * lvl];
    bucket_id = #protect(bucket_id, msf);

    c1 = !c1;
    // is_valid
    tree_bound = tree_path_lower_bound(bucket_id);
    () = #unspill(bpos);
    b = tree_bound <= bpos;
    c2 = #SETcc(b);
    c2 &= c1;
    tree_bound = tree_path_upper_bound(bucket_id);
    () = #unspill(bpos);
    b = tree_bound >= bpos;
    c3 = #SETcc(b);
    c2 &= c3;
    // bucket_has_room
    b = r2 < BLOCKS_PER_BUCKET;
    c3 = #SETcc(b);
    c2 &= c3;
    // not is_empty
    () = #unspill(bid);
    b = bid != EMPTY_BLOCK_ID;
    c3 = #SETcc(b);
    c2 &= c3;
    // is_assigned = cond | is_assigned;
    c1 = !c1;
    c1 |= c2;
    
    // If `b` is true, put it in the bucket: increment the bucket occupancy and set the bucket assignment
    // for this position.
    // increment this, it will only get saved if `b` is true.
    r1 = #LEA(r2 + 1);
    r1 = _ternary(c2, r1, r2);
    () = #unspill(assignment_index, bucket_assignments);
    (u64)[bucket_occupancy + 8 * lvl] = r1;
    r1 = (64u)[bucket_assignments + 8 * assignment_index];
    r1 = #protect(r1, msf);
    tmp = lvl;
    r1 = _ternary(c2, tmp, r1);
    (u64)[bucket_assignments + 8 * assignment_index] = r1;
  }

  return msf;
}

inline
fn _stash_place_empty_blocks(
  reg u64 stash,
  #msf reg u64 msf,
  inline int length
) -> #msf reg u64
{
  // standard variables
  reg u64 curr_bucket num_blocks;
  // pointer variables
  reg u64 blocks bucket_occupancy bucket_assignments;
  // temporary variables
  reg u64 tmp_bo bid i tmp_r offset;
  // boolean variables
  reg u8 c1 c2;
  reg bool b cond;
  inline int j;

  blocks, msf = stash_blocks(stash, msf);
  bucket_occupancy, msf = stash_bucket_occupancy(stash, msf);
  bucket_assignments, msf = stash_bucket_assignments(stash, msf);
  num_blocks, msf = stash_num_blocks(stash, msf);
  curr_bucket = #set0();
  i = 0;
  while { cond = i < num_blocks; } (cond) {
    msf = #update_msf(cond, msf);
    c1 = 0; // found_curr_bucket
    for j = 0 to length
    {
      c1 = !c1;
      // bucket_has_room
      #declassify tmp_bo = (64u)[bucket_occupancy + 8 * j];
      tmp_bo = #protect(tmp_bo, msf);
      b = tmp_bo != BLOCKS_PER_BUCKET;
      c2 = #SETcc(b);
      c2 &= c1;
      // set_curr_bucket
      tmp_r = (64u)j;
      curr_bucket = _ternary(c2, tmp_r, curr_bucket);
      c1 = !c1;
      c1 |= c2;
    }
    tmp_bo = (64u)[bucket_occupancy + 8 * curr_bucket];
    offset = 8 * DECRYPTED_BLOCK_SIZE_QWORDS * i;
    bid = (64u)[blocks + offset];
    // cond_place_in_bucket
    b = bid == EMPTY_BLOCK_ID;
    c2 = #SETcc(b);
    b = tmp_bo < BLOCKS_PER_BUCKET;
    c1 = #SETcc(b);
    c1 &= c2;

    tmp_r = #LEA(tmp_bo + 1);
    tmp_r = _ternary(c1, tmp_r, tmp_bo);
    (u64)[bucket_occupancy + 8 * curr_bucket] = tmp_r;
    tmp_bo = (64u)[bucket_assignments + 8 * i];
    tmp_r = _ternary(c1, curr_bucket, tmp_bo);
    (u64)[bucket_assignments + 8 * i] = tmp_r;
    i += 1;
  }
  msf = #update_msf(!cond, msf);
  // at the end, every bucket should be full
  return msf;
}

inline
fn _stash_assign_buckets(
  reg u64 stash path,
  #msf reg u64 msf,
  inline int length
) -> #msf reg u64
{
  // standard variables
  reg u64 ub num_blocks;
  // pointer variables
  reg u64 bucket_assignments bucket_occupancy;
  // temporary variables
  reg u64 it;
  #mmx reg u64 path_s;
  reg bool cond;
  inline int i lvl;

  // assign all blocks to "overflow" - level UINT64_MAX and set all occupancy to 0
  bucket_assignments, msf = stash_bucket_assignments(stash, msf);
  num_blocks, msf = stash_num_blocks(stash, msf);

  it = 0;
  while {cond = it < num_blocks; } (cond) {
    msf = #update_msf(cond, msf);
    (u64)[bucket_assignments + 8 * it] = (64u)-1; it += 1;
  }
  msf = #update_msf(!cond, msf);
  bucket_occupancy, msf = stash_bucket_occupancy(stash, msf);
  for i = 0 to length { (u64)[bucket_occupancy + 8 * i] = (64u)0; }

  // assign blocks in path to buckets first
  for lvl = 0 to length
  { for i = 0 to BLOCKS_PER_BUCKET
    {
      msf = _stash_assign_block_to_bucket_path(stash, path, lvl * BLOCKS_PER_BUCKET + i, msf);
    }
  }

  path_s = path;
  // assign blocks in overflow to buckets
  #update_after_call ub, msf = _stash_overflow_ub(stash, msf);
  stash = stash;
  stash = #protect(stash, msf);
  path = path_s;
  it = 0;
  while { cond = it < ub; } (cond) {
    msf = #update_msf(cond, msf);
    msf = _stash_assign_block_to_bucket_overflow(stash, path, it, msf, length);
    it = #LEA(it + 1);
  }
  msf = #update_msf(!cond, msf);

  // now assign empty blocks to fill the buckets
  msf = _stash_place_empty_blocks(stash, msf, length);

  return msf;
}

inline
fn _comp_and_swap(
  reg u64 bla0 bla1 b0 b1
)
{
  reg u256 t0 t1 tmp256 mask2 mask3;
  reg u128 r0 r1 tmp128 mask0 mask1;
  reg u64 a b tmp cond0 cond1;
  reg u32 edi;
  reg u8 dil al dl;
  inline int r;
  reg bool cond;
  stack u64 c0_s c1_s;

  a = [bla0];  // block_level_assignments
  b = [bla1];  // block_level_assignments
  tmp = [b0 + 8]; // blocks

  // comp_blocks
  cond = [b1 + 8] < tmp;
  dil = #SETcc(cond);
  cond = a == b;
  al = #SETcc(cond);
  al &= dil;
  cond = a > b;
  dl = #SETcc(cond);
  al |= dl;

  edi = (32u)al;  // cond
  cond0 = (64u)edi;
  cond0 -= 1;
  cond1 = (64u)edi;
  cond1 = -cond1;

  c0_s = cond0;
  c1_s = cond1;
  mask2 = #VPBROADCAST_4u64(c0_s);
  mask3 = #VPBROADCAST_4u64(c1_s);
  // cond_swap_blocks
  for r = 0 to DECRYPTED_BLOCK_SIZE_QWORDS / 4 {
    t0 = (u256)[b0 + r * 32];
    t1 = (u256)[b1 + r * 32];
    tmp256 = t0;
    t1 = #VPAND_256(t1, mask3);
    t0 = #VPAND_256(t0, mask3);
    tmp256 = #VPAND_256(tmp256, mask2);
    t1 = #VPOR_256(t1, tmp256);
    (u256)[b0 + r * 32] = t1;
    t1 = (u256)[b1 + r * 32];
    t1 = #VPAND_256(t1, mask2);
    t0 = #VPOR_256(t0, t1);
    (u256)[b1 + r * 32] = t0;
  }
  mask0 = #VPBROADCAST_2u64(c0_s);
  mask1 = #VPBROADCAST_2u64(c1_s);

  r0 = (u128)[b0 + (DECRYPTED_BLOCK_SIZE_QWORDS / 4) * 32];
  r1 = (u128)[b1 + (DECRYPTED_BLOCK_SIZE_QWORDS / 4) * 32];
  tmp128 = r0;
  r1 = #VPAND_128(r1, mask1);
  r0 = #VPAND_128(r0, mask1);
  tmp128 = #VPAND_128(tmp128, mask0);
  r1 = #VPOR_128(r1, tmp128);
  (u128)[b0 + (DECRYPTED_BLOCK_SIZE_QWORDS / 4) * 32] = r1;
  r1 = (u128)[b1 + (DECRYPTED_BLOCK_SIZE_QWORDS / 4) * 32];
  r1 = #VPAND_128(r1, mask0);
  r0 = #VPOR_128(r0, r1);
  (u128)[b1 + (DECRYPTED_BLOCK_SIZE_QWORDS / 4) * 32] = r0;

  // cond_obv_swap_u64
  tmp = [bla0];
  a = [bla1];
  b = tmp;
  a &= cond1;
  tmp &= cond1;
  b &= cond0;
  a |= b;
  [bla0] = a;
  cond0 &= [bla1];
  tmp |= cond0;
  [bla1] = tmp;
}

inline
fn _odd_even_msort(
  #public reg u64 blocks block_level_assignments,
  reg u64 lb ub,
  #msf reg u64 msf
) -> #msf reg u64
{
  reg u64 n;
  n = ub - lb;
  // if (n <= 1) return;

  // pointer variables
  reg u64 current_assignment next_step rdx rcx;
  // standard variables
  reg u64 i j k mini adjusted_range mod_p block_offset rdi r13 rax;
  // temporary variables
  reg u64 rax_3 b0 b1 bla0 bla1;
  // boolean variables
  reg bool cond;

  current_assignment = #LEA(block_level_assignments + lb * 8);
  k = 1;
  () = #spill(current_assignment);

  while {
    next_step = #LEA(k + k);
    mod_p = #LEA(k - 1); // mod k
    cond = k != 0;
    if (cond) {
      msf = #update_msf(cond, msf);
      while {
        j = mod_p;
        j &= k;
        adjusted_range = n;
        adjusted_range -= k;
        cond = j < adjusted_range;  // j < n-k
        if (cond) {
          msf = #update_msf(cond, msf);
          rax = k * (2 * DECRYPTED_BLOCK_SIZE);
          () = #spill(n);
          r13 = adjusted_range;
          rdi = #LEA(k + k);
          () = #spill(mod_p);
          r13 -= j;
          () = #spill(blocks, rax);
          block_offset = #LEA(lb + j);
          block_offset *= DECRYPTED_BLOCK_SIZE;
          () = #spill(block_level_assignments, lb, adjusted_range);
          rdx = #LEA(block_offset + blocks);
          block_offset = #LEA(k + lb);
          block_offset = #LEA(block_level_assignments + block_offset * 8);
          rcx = rdx;
          () = #spill(block_offset);
          rax_3 = k * DECRYPTED_BLOCK_SIZE;
          () = #spill(rax_3);

          while {
            mini = r13;
            cond = k < r13;
            mini = k if cond;
            cond = mini != 0;
            if (cond) {
              msf = #update_msf(cond, msf);
              () = #spill(rdi);
              () = #unspill(current_assignment);
              current_assignment = #protect(current_assignment, msf);
              mini += j;
              b0 = rcx;
              bla1 = #LEA(j * 8);
              () = #spill(rcx);
              i = j;
              bla0 = #LEA(current_assignment + bla1);
              () = #spill(r13, current_assignment);
              () = #unspill(block_offset);
              block_offset = #protect(block_offset, msf);
              
              bla1 += block_offset;
              () = #spill(block_offset);
              () = #unspill(rax_3);
              rax_3 = #protect(rax_3, msf);
              b1 = #LEA(rax_3 + rcx);
              () = #spill(rax_3);

              while { cond = i != mini; } (cond) {
                reg u64 left right;
                msf = #update_msf(cond, msf);
                left = i;
                left /= next_step;
                left = left;
                right = #LEA(i + k);
                () = #spill(i);
                right /= next_step;
                right = right;
                () = #spill(next_step);
                cond = left == right;
                if (cond) {
                  msf = #update_msf(cond, msf);
                  _comp_and_swap(bla0, bla1, b0, b1);
                } else {
                  msf = #update_msf(!cond, msf);
                }
                () = #unspill(i, next_step);
                i = #protect(i, msf);
                next_step = #protect(next_step, msf);
                i = #LEA(i + 1);
                bla0 = #LEA(bla0 + 8);
                bla1 = #LEA(bla1 + 8);
                b1 = #LEA(b1 + DECRYPTED_BLOCK_SIZE);
                b0 = #LEA(b0 + DECRYPTED_BLOCK_SIZE);
              }
              msf = #update_msf(!cond, msf);
              () = #unspill(rdi, r13, rcx);
              rdi = #protect(rdi, msf);
              r13 = #protect(r13, msf);
              rcx = #protect(rcx, msf);
            } else {
              msf = #update_msf(!cond, msf);
            }
            () = #unspill(rax);
            rax = #protect(rax, msf);
            j = #LEA(j + rdi);
            r13 -= rdi;
            rcx = #LEA(rcx + rax);
            () = #spill(rax);
            () = #unspill(adjusted_range);
            adjusted_range = #protect(adjusted_range, msf);
            cond = j < adjusted_range;
            () = #spill(adjusted_range);
          } (cond) {
            msf = #update_msf(cond, msf);
          }
          msf = #update_msf(!cond, msf);
          () = #unspill(n, mod_p, blocks, block_level_assignments, lb);
          n = #protect(n, msf);
          mod_p = #protect(mod_p, msf);
          blocks = #protect(blocks, msf);
          lb = #protect(lb, msf);
        } else {
          msf = #update_msf(!cond, msf);
        }
        k >>= 1;
        cond = k != 0;
      } (cond) {
        msf = #update_msf(cond, msf);
      }
      msf = #update_msf(!cond, msf);
    } else {
      msf = #update_msf(!cond, msf);
    }
    k = next_step;
    cond = next_step < n;
  } (cond) {
    msf = #update_msf(cond, msf);
  }
  msf = #update_msf(!cond, msf);

  return msf;
}

inline
fn stash_build_path(
  reg u64 stash path,
  #msf reg u64 msf,
  inline int length
) -> #msf reg u64
{
  reg u64 overflow_size;
  reg u64 blocks bucket_assignments;

  msf = _stash_assign_buckets(stash, path, msf, length);

  #update_after_call overflow_size, msf = _stash_overflow_ub(stash, msf);
  stash = stash;
  stash = #protect(stash, msf);
  overflow_size = #LEA(overflow_size + length * BLOCKS_PER_BUCKET);
  
  blocks, msf = stash_blocks(stash, msf);
  bucket_assignments, msf = stash_bucket_assignments(stash, msf);
  
  msf = _odd_even_msort(blocks, bucket_assignments, 0, overflow_size, msf);

  return msf;
}
